{"title": "OPTIMAL CONTROL OF DYNAMICAL SYSTEMS", "level": "5222", "abbreviation": "ME", "description": "This course covers the synthesis of optimal control laws for linear and nonlinear dynamical systems. Necessary conditions for optimal control based on the Pontryagin Minimum Principle will be introduced, and cases of fixed and free terminal time and boundary conditions will be discussed. Feedback optimal control will be discussed, and the Hamilton-Jacobi-Bellman equation will be introduced. The\nspecial case of linear quadratic optimal control will be discussed. Examples throughout the course will be based on air-and-space vehicle applications, such as flight trajectory optimization. Assignments and term project (if any) will introduce basic numerical techniques, and introduce software packages for optimal control.   Prequisites: Fluency with the theory of linear dynamical systems and control is required. Familiarity with MATLAB. Familiarity with air-and-space vehicledynamics is\nbeneficial, but not necessary.", "req": [], "cat1Status": true, "startYear": -1}